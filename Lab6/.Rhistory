string.count <- stri_count_regex(full_df$job_description, make_string) %>%
as.data.frame() %>%
colSums()
skill.count[i,1] <- soft_skills[i,2]
skill.count[i,2] <- string.count
}
View(skill.count)
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
mydb = dbConnect(MySQL('project3'), user='admin', password='project3', host='34.68.107.105', port = 3306)
full_df <- dbGetQuery(mydb, 'SELECT * FROM project3.project3_all')
soft_skills <- dbGetQuery(mydb, 'SELECT * FROM project3.skills_text')
# scrape_df$job_description <- sapply(scrape_df$job_description,function(row) iconv(row, "latin1", "ASCII", sub=""))
jobs.corpus <- VCorpus(VectorSource(full_df$job_description))
# # 1. Stripping any extra white space:
jobs.corpus <- tm_map(jobs.corpus, stripWhitespace)
# # 2. Transforming everything to lowercase
jobs.corpus <- tm_map(jobs.corpus, content_transformer(tolower))
# # 3. Removing numbers
jobs.corpus <- tm_map(jobs.corpus, removeNumbers)
# 4. Removing punctuation
jobs.corpus <- tm_map(jobs.corpus, removePunctuation)
# 5. Removing stop words
jobs.corpus <- tm_map(jobs.corpus, removeWords, stopwords("english"))
jobs.corpus[[1]]$content
jobs.corpus <- tm_map(jobs.corpus, stemDocument)
jobs.corpus[[1]]$content
DTM <- DocumentTermMatrix(jobs.corpus)
inspect(DTM)
sums <- as.data.frame(colSums(as.matrix(DTM)))
sums <- rownames_to_column(sums)
colnames(sums) <- c("term", "count")
sums <- arrange(sums, desc(count))
head <- sums[1:75,]
test <- TermDocumentMatrix(jobs.corpus)
inspect(test)
slam::row_sums(test)
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
mydb = dbConnect(MySQL('project3'), user='admin', password='project3', host='34.68.107.105', port = 3306)
full_df <- dbGetQuery(mydb, 'SELECT * FROM project3.project3_all')
soft_skills <- dbGetQuery(mydb, 'SELECT * FROM project3.skills_text')
# scrape_df$job_description <- sapply(scrape_df$job_description,function(row) iconv(row, "latin1", "ASCII", sub=""))
jobs.corpus <- VCorpus(VectorSource(full_df$job_description))
# # 1. Stripping any extra white space:
jobs.corpus <- tm_map(jobs.corpus, stripWhitespace)
# # 2. Transforming everything to lowercase
jobs.corpus <- tm_map(jobs.corpus, content_transformer(tolower))
# # 3. Removing numbers
jobs.corpus <- tm_map(jobs.corpus, removeNumbers)
# 4. Removing punctuation
jobs.corpus <- tm_map(jobs.corpus, removePunctuation)
# 5. Removing stop words
jobs.corpus <- tm_map(jobs.corpus, removeWords, stopwords("english"))
jobs.corpus[[1]]$content
jobs.corpus <- tm_map(jobs.corpus, stemDocument)
jobs.corpus[[1]]$content
DTM <- DocumentTermMatrix(jobs.corpus)
inspect(DTM)
soft_skills <- soft_skills %>%
mutate(Text = tolower(Text))
full_df <- full_df %>%
mutate(job_description = tolower(job_description))
skill.count <- data.frame(matrix(NA, nrow = 181, ncol = 2))
rows_soft_skils <- nrow(soft_skills)
for (i in 1:rows_soft_skils) {
make_string <- soft_skills[i,2] %>% as.String()
string.count <- stri_count_regex(full_df$job_description, make_string) %>%
as.data.frame() %>%
colSums()
skill.count[i,1] <- soft_skills[i,2]
skill.count[i,2] <- string.count
}
View(skill.count)
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
mydb = dbConnect(MySQL('project3'), user='admin', password='project3', host='34.68.107.105', port = 3306)
full_df <- dbGetQuery(mydb, 'SELECT * FROM project3.project3_all')
soft_skills <- dbGetQuery(mydb, 'SELECT * FROM project3.skills_text')
# scrape_df$job_description <- sapply(scrape_df$job_description,function(row) iconv(row, "latin1", "ASCII", sub=""))
jobs.corpus <- VCorpus(VectorSource(full_df$job_description))
# # 1. Stripping any extra white space:
jobs.corpus <- tm_map(jobs.corpus, stripWhitespace)
# # 2. Transforming everything to lowercase
jobs.corpus <- tm_map(jobs.corpus, content_transformer(tolower))
# # 3. Removing numbers
jobs.corpus <- tm_map(jobs.corpus, removeNumbers)
# 4. Removing punctuation
jobs.corpus <- tm_map(jobs.corpus, removePunctuation)
# 5. Removing stop words
jobs.corpus <- tm_map(jobs.corpus, removeWords, stopwords("english"))
jobs.corpus[[1]]$content
jobs.corpus <- tm_map(jobs.corpus, stemDocument)
jobs.corpus[[1]]$content
DTM <- DocumentTermMatrix(jobs.corpus)
inspect(DTM)
soft_skills <- soft_skills %>%
mutate(Text = tolower(Text))
job_descriptions <- full_df %>%
mutate(job_description = tolower(job_description)) %>%
select(job_description)
final_df <- data.frame(matrix(NA, nrow = 181, ncol = 2))
rows_soft_skils <- nrow(soft_skills)
for (i in 1:rows_soft_skils) {
make_string <- soft_skills[i,2] %>% as.String()
frequency <- stri_count_regex(job_descriptions, make_string) %>%
as.data.frame() %>%
colSums()
final_df[i,1] <- soft_skills[i,2]
final_df[i,2] <- frequency()
}
View(final_df)
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
mydb = dbConnect(MySQL('project3'), user='admin', password='project3', host='34.68.107.105', port = 3306)
full_df <- dbGetQuery(mydb, 'SELECT * FROM project3.project3_all')
soft_skills <- dbGetQuery(mydb, 'SELECT * FROM project3.skills_text')
# scrape_df$job_description <- sapply(scrape_df$job_description,function(row) iconv(row, "latin1", "ASCII", sub=""))
jobs.corpus <- VCorpus(VectorSource(full_df$job_description))
# # 1. Stripping any extra white space:
jobs.corpus <- tm_map(jobs.corpus, stripWhitespace)
# # 2. Transforming everything to lowercase
jobs.corpus <- tm_map(jobs.corpus, content_transformer(tolower))
# # 3. Removing numbers
jobs.corpus <- tm_map(jobs.corpus, removeNumbers)
# 4. Removing punctuation
jobs.corpus <- tm_map(jobs.corpus, removePunctuation)
# 5. Removing stop words
jobs.corpus <- tm_map(jobs.corpus, removeWords, stopwords("english"))
jobs.corpus[[1]]$content
jobs.corpus <- tm_map(jobs.corpus, stemDocument)
jobs.corpus[[1]]$content
DTM <- DocumentTermMatrix(jobs.corpus)
inspect(DTM)
soft_skills <- soft_skills %>%
mutate(Text = tolower(Text))
full_df <- full_df %>%
mutate(job_description = tolower(job_description))
final_df <- data.frame(matrix(NA, nrow = 181, ncol = 2))
rows_soft_skils <- nrow(soft_skills)
for (i in 1:rows_soft_skils) {
make_string <- soft_skills[i,2] %>% as.String()
frequency <- stri_count_regex(full_df$job_description, make_string) %>%
as.data.frame() %>%
colSums()
final_df[i,1] <- soft_skills[i,2]
final_df[i,2] <- frequency()
}
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
mydb = dbConnect(MySQL('project3'), user='admin', password='project3', host='34.68.107.105', port = 3306)
full_df <- dbGetQuery(mydb, 'SELECT * FROM project3.project3_all')
soft_skills <- dbGetQuery(mydb, 'SELECT * FROM project3.skills_text')
# scrape_df$job_description <- sapply(scrape_df$job_description,function(row) iconv(row, "latin1", "ASCII", sub=""))
jobs.corpus <- VCorpus(VectorSource(full_df$job_description))
# # 1. Stripping any extra white space:
jobs.corpus <- tm_map(jobs.corpus, stripWhitespace)
# # 2. Transforming everything to lowercase
jobs.corpus <- tm_map(jobs.corpus, content_transformer(tolower))
# # 3. Removing numbers
jobs.corpus <- tm_map(jobs.corpus, removeNumbers)
# 4. Removing punctuation
jobs.corpus <- tm_map(jobs.corpus, removePunctuation)
# 5. Removing stop words
jobs.corpus <- tm_map(jobs.corpus, removeWords, stopwords("english"))
jobs.corpus[[1]]$content
jobs.corpus <- tm_map(jobs.corpus, stemDocument)
jobs.corpus[[1]]$content
DTM <- DocumentTermMatrix(jobs.corpus)
inspect(DTM)
soft_skills <- soft_skills %>%
mutate(Text = tolower(Text))
full_df <- full_df %>%
mutate(job_description = tolower(job_description))
final_df <- data.frame(matrix(NA, nrow = 181, ncol = 2))
rows_soft_skils <- nrow(soft_skills)
for (i in 1:rows_soft_skils) {
make_string <- soft_skills[i,2] %>% as.String()
frequency <- stri_count_regex(full_df$job_description, make_string) %>%
as.data.frame() %>%
colSums()
final_df[i,1] <- soft_skills[i,2]
final_df[i,2] <- frequency
}
View(final_df)
?stri_count_regex()
soft_skills <- soft_skills %>%
mutate(Text = tolower(Text)) %>%
mutate(Text = str_sub(Text, end = -2L))
for (i in 1:rows_soft_skils) {
make_string <- soft_skills[i,2] %>% as.String()
frequency <- stri_count_regex(full_df$job_description, make_string) %>%
as.data.frame() %>%
colSums()
final_df[i,1] <- soft_skills[i,2]
final_df[i,2] <- frequency
}
View(final_df)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap2.csv')
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
full_df <- read.csv('C:/Users/zalexander/Desktop/IndeedScrapV2.csv')
full_df <- full_df %>%
mutate(job_description = tolower(job_description))
final_df <- data.frame(matrix(NA, nrow = length(soft_skills$Text), ncol = 2))
rows_soft_skils <- nrow(soft_skills)
for (i in 1:rows_soft_skils) {
make_string <- soft_skills[i,2] %>% as.String()
frequency <- stri_count_regex(full_df$job_description, make_string) %>%
as.data.frame() %>%
colSums()
final_df[i,1] <- soft_skills[i,2]
final_df[i,2] <- frequency
}
View(final_df)
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
full_df <- read.csv('C:/Users/zalexander/Desktop/IndeedScrapV2.csv')
mydb = dbConnect(MySQL('project3'), user='admin', password='project3', host='34.68.107.105', port = 3306)
# full_df <- dbGetQuery(mydb, 'SELECT * FROM project3.project3_all')
soft_skills <- dbGetQuery(mydb, 'SELECT * FROM project3.skills_text')
# scrape_df$job_description <- sapply(scrape_df$job_description,function(row) iconv(row, "latin1", "ASCII", sub=""))
jobs.corpus <- VCorpus(VectorSource(full_df$job_description))
# # 1. Stripping any extra white space:
jobs.corpus <- tm_map(jobs.corpus, stripWhitespace)
# # 2. Transforming everything to lowercase
jobs.corpus <- tm_map(jobs.corpus, content_transformer(tolower))
# # 3. Removing numbers
jobs.corpus <- tm_map(jobs.corpus, removeNumbers)
# 4. Removing punctuation
jobs.corpus <- tm_map(jobs.corpus, removePunctuation)
# 5. Removing stop words
jobs.corpus <- tm_map(jobs.corpus, removeWords, stopwords("english"))
jobs.corpus[[1]]$content
jobs.corpus <- tm_map(jobs.corpus, stemDocument)
jobs.corpus[[1]]$content
DTM <- DocumentTermMatrix(jobs.corpus)
inspect(DTM)
soft_skills <- soft_skills %>%
mutate(Text = tolower(Text)) %>%
mutate(Text = str_sub(Text, end = -2L))
full_df <- full_df %>%
mutate(job_description = tolower(job_description))
final_df <- data.frame(matrix(NA, nrow = length(soft_skills$Text), ncol = 2))
rows_soft_skils <- nrow(soft_skills)
for (i in 1:rows_soft_skils) {
make_string <- soft_skills[i,2] %>% as.String()
frequency <- stri_count_regex(full_df$job_description, make_string) %>%
as.data.frame() %>%
colSums()
final_df[i,1] <- soft_skills[i,2]
final_df[i,2] <- frequency
}
url <- "https://towardsdatascience.com/top-skills-every-data-scientist-needs-to-master-5aba4293b88"
page <- xml2::read_html(url)
page %>%
rvest::html_nodes("div") %>%
rvest::html_nodes(xpath = '//strong[@mo.na]')
page %>%
rvest::html_nodes("div") %>%
page %>%
rvest::html_nodes("div") %>%
rvest::html_nodes(xpath = '//strong[@mo.na]')
page %>%
rvest::html_nodes("div")
page %>%
rvest::html_nodes("div") %>%
rvest::html_nodes("strong")
page %>%
rvest::html_nodes("div") %>%
rvest::html_nodes("strong") %>%
rvest::html_nodes("text")
page %>%
rvest::html_nodes("div") %>%
rvest::html_nodes("strong") %>%
rvest::html_text()
skills_1 <- page %>%
rvest::html_nodes("div") %>%
rvest::html_nodes("strong") %>%
rvest::html_text()
skills_1 <- skills_1[2,10]
skills_1 <- skills_1[c(2,10)]
skills_1 <- page %>%
rvest::html_nodes("div") %>%
rvest::html_nodes("strong") %>%
rvest::html_text()
skills_1 <- skills_1[c(2:10)]
url_2 <- "https://www.thebalancecareers.com/list-of-data-scientist-skills-2062381"
page_2 <- xml2::read_html(url)
skills_2 <- page_2 %>%
rvest::html_nodes('#text') %>%
rvest::html_text()
skills_2 <- page_2 %>%
rvest::html_nodes('[id=text]') %>%
rvest::html_text()
skills_2 <- page_2 %>%
rvest::html_nodes("[id='text']") %>%
rvest::html_text()
skills_2 <- page_2 %>%
rvest::html_nodes("#text") %>%
rvest::html_text()
page_2
page_2 %>% rvest::html_nodes('li')
page_2 %>% rvest::html_nodes('li') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('li') %>% rvest::html_nodes('#text') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('li') %>% rvest::html_nodes('li') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('div') %>% rvest::html_nodes('ul') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('div') %>% rvest::html_nodes('ul') %>% rvest::html_children('li') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('div') %>% rvest::html_children('ul, li') %>% rvest::html_text()
?html_children
page_2 %>% rvest::html_nodes('div') %>% rvest::html_children('li') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('div') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('div') %>% rvest::html_nodes('ul') %>% rvest::html_text()
page_2 %>% rvest::html_nodes('div') %>% rvest::html_nodes('ul') %>% rvest::html_nodes('li') %>% rvest::html_text()
page_2 %>% rvest::html_node('.comp.mntl-sc-block.mntl-sc-block-html') %>% rvest::html_nodes('ul') %>% rvest::html_nodes('li') %>% rvest::html_text()
page_2 %>% rvest::html_node('.comp.mntl-sc-block.mntl-sc-block-html')
page_2 %>% rvest::html_nodes('comp.mntl-sc-block.mntl-sc-block-html')
page_2 %>% rvest::html_nodes('#mntl-sc-block_1-0-14.comp.mn.tl-sc-block.mntl-sc-block-html')
page_2 %>% rvest::html_node('#mntl-sc-block_1-0-14.comp.mn.tl-sc-block.mntl-sc-block-html')
page_2 %>% rvest::html_node('mntl-sc-block_1-0-14.comp.mn.tl-sc-block.mntl-sc-block-html')
page_2 %>% str_extract_all(page_2, 'comp mntl-sc-block mntl-sc-block-html')
page_2 %>% str_extract_all('comp mntl-sc-block mntl-sc-block-html')
page_2 %>% unlist(str_extract_all('<class = "comp mntl-sc-block mntl-sc-block-html">)
class="comp mntl-sc-block mntl-sc-block-html"
class="comp mntl-sc-block mntl-sc-block-html"
class="comp mntl-sc-block mntl-sc-block-html"
class="comp mntl-sc-block mntl-sc-block-html"
page_2 %>% unlist(str_extract_all('<class = "comp mntl-sc-block mntl-sc-block-html">)
page_2 %>% unlist(str_extract_all('<class = "comp mntl-sc-block mntl-sc-block-html">')
page_2 %>% unlist(str_extract_all('<class = "comp mntl-sc-block mntl-sc-block-html">')
page_2 %>% unlist(str_extract_all('<class = "comp mntl-sc-block mntl-sc-block-html">'))
page_2 %>% unlist(str_extract_all(page_2, '<class = "comp mntl-sc-block mntl-sc-block-html">'))
page_2 %>% rvest::html_children('li')
page_2 %>% rvest::html_attrs()
page_2 %>% rvest::html_attr(page_2, "class")
page_2 %>% rvest::html_attr("class")
page_2 %>% rvest::html_attr(".comp.mntl-sc-block.mntl-sc-block-html")
page_2 %>% rvest::html_nodes('div') %>% rvest::html_nodes('ul') %>% rvest::html_nodes('li') %>% rvest::html_text()
url_2 <- "https://www.cio.com/article/3263790/the-essential-skills-and-traits-of-an-expert-data-scientist.html"
page_2 <- xml2::read_html(url)
skills_2 <- page_2 %>%
rvest::html_nodes("h2") %>%
rvest::html_text()
skills_2
url_2 <- "https://www.kdnuggets.com/2019/07/top-13-skills-become-rockstar-data-scientist.html"
page_2 <- xml2::read_html(url)
skills_2 <- page_2 %>%
rvest::html_nodes("h3") %>%
rvest::html_text()
skills_2 <- page_2 %>%
rvest::html_nodes("div") %>%
rvest::html_nodes("h3") %>%
rvest::html_text()
page_2 %>% rvest::html_nodes("div")
page_2 %>% rvest::html_nodes("div") %>% rvest:html_node('h3')
page_2 %>% rvest::html_nodes("div") %>% rvest::html_node('h3')
page_2 %>% rvest::html_nodes("div") %>% rvest::html_nodes('h3')
page_2 %>% rvest::html_nodes("div") %>% rvest::html_nodes('p')
url_2 <- "https://www.thebalancecareers.com/list-of-data-scientist-skills-2062381"
page_2 <- xml2::read_html(url_2)
skills_2 <- page_2 %>%
rvest::html_nodes("#text") %>%
rvest::html_text()
page_2 %>% rvest::html_nodes('div') %>% rvest::html_nodes('ul') %>% rvest::html_nodes('li') %>% rvest::html_text()
skills_2 <- page_2 %>%
rvest::html_nodes('div') %>%
rvest::html_nodes('ul') %>%
rvest::html_nodes('li') %>%
rvest::html_text()
skills_2 <- skills_2[c(7:96)]
skills_fnl <- append(skills_1, skills_2)
skills_df <- data.frame(matrix(NA, nrow = length(skills_fnl), ncol = 2))
View(skills_df)
skills_df <- data.frame(matrix(NA, nrow = length(skills_fnl), ncol = 2))
skills_df <- skills_df %>%
mutate(X1 = nrow(1:length(skills_fnl)),
X2 = skills_fnl)
View(skills_df)
skills_df <- skills_df %>%
mutate(X1 = nrow(1:length(skills_fnl)),
X2 = skills_fnl) %>%
mutate(X1 = seq.int(nrow(skills_df)))
skills_df <- data.frame(matrix(NA, nrow = length(skills_fnl), ncol = 2))
skills_df <- skills_df %>%
mutate(X1 = seq.int(nrow(1:length(skills_fnl))),
X2 = skills_fnl)
skills_df <- skills_df %>%
mutate(X1 = nrow(1:length(skills_fnl)),
X2 = skills_fnl) %>%
mutate(X1 = seq.int(nrow(skills_df))) %>%
select(X1, X2)
View(skills_df)
skills_df <- skills_df %>%
mutate(X1 = nrow(1:length(skills_fnl)),
X2 = skills_fnl) %>%
mutate(X1 = seq.int(nrow(skills_df))) %>%
select(X1, X2) %>%
mutate(X2 = toLower(X2))
skills_df <- skills_df %>%
mutate(X1 = nrow(1:length(skills_fnl)),
X2 = skills_fnl) %>%
mutate(X1 = seq.int(nrow(skills_df))) %>%
select(X1, X2) %>%
mutate(X2 = tolower(X2))
View(skills_df)
skills_df <- skills_df %>%
mutate(X1 = nrow(1:length(skills_fnl)),
X2 = skills_fnl) %>%
mutate(X1 = seq.int(nrow(skills_df))) %>%
select(X1, X2) %>%
mutate(X2 = tolower(X2)) %>%
distinct()
write.csv(skills_df, file = "C:/Users/zalexander/Desktop/data607_cunysps/Project3/more_skills.csv")
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
# full_df <- read.csv('C:/Users/zalexander/Desktop/indeedscrap.csv')
full_df <- read.csv('C:/Users/zalexander/Desktop/IndeedScrapV2.csv')
url_1 <- "https://towardsdatascience.com/top-skills-every-data-scientist-needs-to-master-5aba4293b88"
page_1 <- xml2::read_html(url)
url_1 <- "https://towardsdatascience.com/top-skills-every-data-scientist-needs-to-master-5aba4293b88"
page_1 <- xml2::read_html(url)
knitr::opts_chunk$set(echo = TRUE)
library(dbConnect)
library(rvest)
library(dplyr)
library(tm)
library(SnowballC)
library(RCurl)
library(XML)
library(RColorBrewer)
library(tidyverse)
library(stringr)
library(stringi)
library(xml2)
url_1 <- "https://towardsdatascience.com/top-skills-every-data-scientist-needs-to-master-5aba4293b88"
page_1 <- xml2::read_html(url)
